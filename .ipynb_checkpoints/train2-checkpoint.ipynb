{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential  \n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.layers.wrappers import Bidirectional\n",
    "from keras.callbacks import EarlyStopping, CSVLogger\n",
    "import math    \n",
    "\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#%matplotlib inline\n",
    "\n",
    "dataframe = pd.read_csv(\"./TrainingSet.csv\")\n",
    "print dataframe.shape\n",
    "dataframe = dataframe.dropna()\n",
    "print dataframe.shape\n",
    "dataframe.head()\n",
    "\n",
    "dataframe.drop([\"YYYYMM\"],axis=1,inplace=True)\n",
    "dataset = dataframe.values\n",
    "print dataset\n",
    "dataset = dataset.astype(\"float32\")\n",
    "dataset = minmax_scale(dataset)\n",
    "print \"-\"*20\n",
    "print dataset\n",
    "\n",
    "train_size = int(len(dataset) * 0.67)\n",
    "test_size = len(dataset) - train_size\n",
    "train, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]\n",
    "print(len(train), len(test))\n",
    "\n",
    "def split_xy(dataset):\n",
    "    dataX = dataset[:,1:]\n",
    "    dataY = dataset[:,0]\n",
    "    return np.array(dataX),np.array([dataY]).T\n",
    "trainX, trainY = split_xy(train)\n",
    "testX,testY = split_xy(test)\n",
    "\n",
    "hidden_neurons = 20\n",
    "in_out_neurons = 1\n",
    "epochs = 100\n",
    "batch_size = 3\n",
    "\n",
    "def FCNN(hidden_neurons=20):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(hidden_neurons,input_dim=12))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(Dense(output_dim=1))\n",
    "    model.add(Activation(\"linear\"))\n",
    "    return model\n",
    "\n",
    "model = FCNN()\n",
    "model.compile(loss=\"mean_squared_error\",optimizer=\"adam\",metrics=[\"accuracy\"])\n",
    "es = EarlyStopping(monitor='val_loss', patience=2)\n",
    "csv_logger = CSVLogger('training.log')          \n",
    "hist = model.fit(trainX,trainY,nb_epoch=epochs, batch_size=batch_size,\n",
    "                    verbose=1,validation_data=(testX, testY),callbacks=[es, csv_logger],shuffle=False)\n",
    "scores = model.evaluate(testX, testY, batch_size=batch_size,verbose=0)\n",
    "\n",
    "print('test score:', scores[0])\n",
    "print('test accuracy:', scores[1])\n",
    "\n",
    "\n",
    "trainPredict = model.predict(trainX)\n",
    "testPredict = model.predict(testX)\n",
    "\n",
    "#Plot\n",
    "plt.legend(loc='best')\n",
    "plt.grid()\n",
    "plt.xlabel(\"predict\")\n",
    "plt.ylabel(\"actual\")\n",
    "plt.plot(trainPredict,trainY)\n",
    "plt.show()\n",
    "plt.savefig(\"train_fcnn.png\")\n",
    "\n",
    "plt.legend(loc='best')\n",
    "plt.grid()\n",
    "plt.xlabel(\"predict\")\n",
    "plt.ylabel(\"actual\")\n",
    "plt.plot(testPredict,testY)\n",
    "plt.show()\n",
    "plt.savefig(\"test_fcnn.png\")\n",
    "\n",
    "loss = hist.history['loss']\n",
    "val_loss = hist.history['val_loss']\n",
    "epochs = len(loss)\n",
    "plt.plot(range(epochs), loss, marker='.', label='acc')\n",
    "plt.plot(range(epochs), val_loss, marker='.', label='val_acc')\n",
    "plt.legend(loc='best')\n",
    "plt.grid()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('acc')\n",
    "plt.show()\n",
    "plt.savefig(\"acc_fcnn.png\")\n",
    "\n",
    "#trainPredict = scaler.inverse_transform(trainPredict)\n",
    "#trainY = scaler.inverse_transform([trainY])\n",
    "#testPredict = scaler.inverse_transform(testPredict)\n",
    "#testY = scaler.inverse_transform([testY])\n",
    "#trainScore = math.sqrt(mean_squared_error(trainY[0], trainPredict[:,0]))\n",
    "\n",
    "def Simple_LSTM(hidden_neurons=20):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(hidden_neurons, input_dim=1))\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation(\"linear\"))\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "model = Simple_LSTM()\n",
    "model.compile(loss=\"mean_squared_error\",optimizer=\"adam\",metrics=[\"accuracy\"])\n",
    "es = EarlyStopping(monitor='val_loss', patience=2)\n",
    "csv_logger = CSVLogger('training.log')          \n",
    "hist = model.fit(trainX,trainY,nb_epoch=epochs, batch_size=batch_size,\n",
    "                    verbose=1,validation_data=(testX, testY),callbacks=[es, csv_logger],shuffle=False)\n",
    "scores = model.evaluate(testX, testY, batch_size=batch_size,verbose=0)\n",
    "\n",
    "print('test score:', scores[0])\n",
    "print('test accuracy:', scores[1])\n",
    "\n",
    "trainPredict = model.predict(trainX)\n",
    "testPredict = model.predict(testX)\n",
    "\n",
    "\n",
    "plt.legend(loc='best')\n",
    "plt.grid()\n",
    "plt.xlabel(\"predict\")\n",
    "plt.ylabel(\"actual\")\n",
    "plt.plot(trainPredict,trainY)\n",
    "plt.show()\n",
    "plt.savefig(\"train_slstm.png\")\n",
    "\n",
    "plt.legend(loc='best')\n",
    "plt.grid()\n",
    "plt.xlabel(\"predict\")\n",
    "plt.ylabel(\"actual\")\n",
    "plt.plot(testPredict,testY)\n",
    "plt.show()\n",
    "plt.savefig(\"test_slstm.png\")\n",
    "\n",
    "loss = hist.history['loss']\n",
    "val_loss = hist.history['val_loss']\n",
    "\n",
    "epochs = len(loss)\n",
    "plt.plot(range(epochs), loss, marker='.', label='acc')\n",
    "plt.plot(range(epochs), val_loss, marker='.', label='val_acc')\n",
    "plt.legend(loc='best')\n",
    "plt.grid()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('acc')\n",
    "plt.show()\n",
    "plt.savefig(\"acc_slstm.png\")\n",
    "\n",
    "def Dropout_LSTM(hidden_neurons=20):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(hidden_neurons, input_dim=12))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation(\"linear\"))\n",
    "    return model\n",
    "\n",
    "model = Dropout_LSTM()\n",
    "model.compile(loss=\"mean_squared_error\",optimizer=\"adam\",metrics=[\"accuracy\"])\n",
    "es = EarlyStopping(monitor='val_loss', patience=2)\n",
    "csv_logger = CSVLogger('training.log')          \n",
    "hist = model.fit(trainX,trainY,nb_epoch=epochs, batch_size=batch_size,\n",
    "                    verbose=1,validation_data=(testX, testY),callbacks=[es, csv_logger],shuffle=False)\n",
    "scores = model.evaluate(testX, testY, batch_size=batch_size,verbose=0)\n",
    "\n",
    "print('test score:', scores[0])\n",
    "print('test accuracy:', scores[1])\n",
    "\n",
    "trainPredict = model.predict(trainX)\n",
    "testPredict = model.predict(testX)\n",
    "              \n",
    "              \n",
    "plt.legend(loc='best')\n",
    "plt.grid()\n",
    "plt.xlabel(\"predict\")\n",
    "plt.ylabel(\"actual\")\n",
    "plt.plot(trainPredict,trainY)\n",
    "plt.show()\n",
    "plt.savefig(\"train_dlstm.png\")\n",
    "\n",
    "plt.legend(loc='best')\n",
    "plt.grid()\n",
    "plt.xlabel(\"predict\")\n",
    "plt.ylabel(\"actual\")\n",
    "plt.plot(testPredict,testY)\n",
    "plt.show()\n",
    "plt.savefig(\"test_dlstm.png\")\n",
    "\n",
    "loss = hist.history['loss']\n",
    "val_loss = hist.history['val_loss']\n",
    "\n",
    "epochs = len(loss)\n",
    "plt.plot(range(epochs), loss, marker='.', label='acc')\n",
    "plt.plot(range(epochs), val_loss, marker='.', label='val_acc')\n",
    "plt.legend(loc='best')\n",
    "plt.grid()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('acc')\n",
    "plt.show()\n",
    "plt.savefig(\"acc_dlstm.png\")\n",
    "\n",
    "def B_LSTM(hidden_neurons=20):\n",
    "    model = Sequential()\n",
    "    model.add(Bidirectional(LSTM(hidden_neurons,input_dim=12)))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation(\"linear\"))\n",
    "    return model\n",
    "\n",
    "model = B_LSTM()\n",
    "model.compile(loss=\"mean_squared_error\",optimizer=\"adam\",metrics=[\"accuracy\"])\n",
    "es = EarlyStopping(monitor='val_loss', patience=2)\n",
    "csv_logger = CSVLogger('training.log')          \n",
    "hist = model.fit(trainX,trainY,nb_epoch=epochs, batch_size=batch_size,\n",
    "                    verbose=1,validation_data=(testX, testY),callbacks=[es, csv_logger],shuffle=False)\n",
    "scores = model.evaluate(testX, testY, batch_size=batch_size,verbose=0)\n",
    "\n",
    "print('test score:', scores[0])\n",
    "print('test accuracy:', scores[1])\n",
    "\n",
    "trainPredict = model.predict(trainX)\n",
    "testPredict = model.predict(testX)\n",
    "              \n",
    "              \n",
    "plt.legend(loc='best')\n",
    "plt.grid()\n",
    "plt.xlabel(\"predict\")\n",
    "plt.ylabel(\"actual\")\n",
    "plt.plot(trainPredict,trainY)\n",
    "plt.show()\n",
    "plt.savefig(\"train_blstm.png\")\n",
    "\n",
    "plt.legend(loc='best')\n",
    "plt.grid()\n",
    "plt.xlabel(\"predict\")\n",
    "plt.ylabel(\"actual\")\n",
    "plt.plot(testPredict,testY)\n",
    "plt.show()\n",
    "plt.savefig(\"test_blstm.png\")\n",
    "\n",
    "loss = hist.history['loss']\n",
    "val_loss = hist.history['val_loss']\n",
    "\n",
    "epochs = len(loss)\n",
    "plt.plot(range(epochs), loss, marker='.', label='acc')\n",
    "plt.plot(range(epochs), val_loss, marker='.', label='val_acc')\n",
    "plt.legend(loc='best')\n",
    "plt.grid()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('acc')\n",
    "plt.show()\n",
    "plt.savefig(\"acc_blstm.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
